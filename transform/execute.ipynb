{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58048bab-a8cf-4a63-9819-e35c98942ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89efd435-ef6f-4dde-8feb-89dee2afbb27",
   "metadata": {},
   "source": [
    "# Initializing the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd605c88-9679-40c9-bc09-399b237f0ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/24 22:30:53 WARN Utils: Your hostname, prajwal resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "25/08/24 22:30:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/home/prajwal/Movie%20Recomender%20System/pyspark/venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/prajwal/.ivy2/cache\n",
      "The jars for the packages stored in: /home/prajwal/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-8983302d-46c1-4fa7-86c4-99337988ebb6;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;6.0.2 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-s3;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.12.500 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound joda-time#joda-time;2.8.1 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.12.500 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound org.jsoup#jsoup;1.18.2 in central\n",
      "\tfound jakarta.mail#jakarta.mail-api;2.1.3 in central\n",
      "\tfound jakarta.activation#jakarta.activation-api;2.1.3 in central\n",
      "\tfound org.eclipse.angus#angus-mail;2.0.3 in central\n",
      "\tfound org.eclipse.angus#angus-activation;2.0.2 in central\n",
      "\tfound org.apache.poi#poi-ooxml;4.1.2 in central\n",
      "\tfound org.apache.poi#poi;4.1.2 in central\n",
      "\tfound org.apache.commons#commons-collections4;4.4 in central\n",
      "\tfound org.apache.commons#commons-math3;3.6.1 in central\n",
      "\tfound com.zaxxer#SparseBitSet;1.2 in central\n",
      "\tfound org.apache.poi#poi-ooxml-schemas;4.1.2 in central\n",
      "\tfound org.apache.xmlbeans#xmlbeans;3.1.0 in central\n",
      "\tfound org.apache.commons#commons-compress;1.19 in central\n",
      "\tfound com.github.virtuald#curvesapi;1.06 in central\n",
      "\tfound org.apache.poi#poi-scratchpad;4.1.2 in central\n",
      "\tfound org.apache.pdfbox#pdfbox;2.0.28 in central\n",
      "\tfound org.apache.pdfbox#fontbox;2.0.28 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.19.2 in central\n",
      "\tfound com.johnsnowlabs.nlp#jsl-llamacpp-cpu_2.12;0.1.6 in central\n",
      "\tfound org.jetbrains#annotations;24.1.0 in central\n",
      "\tfound com.johnsnowlabs.nlp#jsl-openvino-cpu_2.12;0.1.0 in central\n",
      ":: resolution report :: resolve 1868ms :: artifacts dl 76ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.12.500 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.github.virtuald#curvesapi;1.06 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#jsl-llamacpp-cpu_2.12;0.1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#jsl-openvino-cpu_2.12;0.1.0 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;6.0.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.19.2 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcom.zaxxer#SparseBitSet;1.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjakarta.activation#jakarta.activation-api;2.1.3 from central in [default]\n",
      "\tjakarta.mail#jakarta.mail-api;2.1.3 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\tjoda-time#joda-time;2.8.1 from central in [default]\n",
      "\torg.apache.commons#commons-collections4;4.4 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.19 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.6.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.apache.pdfbox#fontbox;2.0.28 from central in [default]\n",
      "\torg.apache.pdfbox#pdfbox;2.0.28 from central in [default]\n",
      "\torg.apache.poi#poi;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-ooxml;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-ooxml-schemas;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-scratchpad;4.1.2 from central in [default]\n",
      "\torg.apache.xmlbeans#xmlbeans;3.1.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.eclipse.angus#angus-activation;2.0.2 from central in [default]\n",
      "\torg.eclipse.angus#angus-mail;2.0.3 from central in [default]\n",
      "\torg.jetbrains#annotations;24.1.0 from central in [default]\n",
      "\torg.jsoup#jsoup;1.18.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\tcommons-codec#commons-codec;1.13 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |  104  |   0   |   0   |   6   ||   98  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-8983302d-46c1-4fa7-86c4-99337988ebb6\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 98 already retrieved (0kB/20ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/24 22:30:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/24 22:30:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MovieDataTransform\") \\\n",
    "    .config(\"spark.driver.memory\", \"5g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"16\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1000M\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:6.0.2\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2268a8-5f84-4951-bc11-45d73fca798c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MovieDataTransform</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7bf2240daed0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d16ebe7-3fd4-4e8c-9772-5d29c21025cb",
   "metadata": {},
   "source": [
    "# Reading the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f768b302-c9ea-418d-b562-9b90724e7b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d109bc6-a735-4528-8c76-a0d9eefbf4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#input_dir = /home/prajwal/Movie-Data/Extraction\n",
    "movie_df = spark.read.csv(os.path.join(\"/home/prajwal/Movie-Data/Extraction\", \"IMDB TMDB Movie Metadata Big Dataset (1M).csv\"),\n",
    "                            header=True,\n",
    "                            inferSchema=True,\n",
    "                            quote='\"',                  # handle quoted strings\n",
    "                            escape='\"',                 # handle quotes inside fields\n",
    "                            multiLine=True,              # allow multi-line fields\n",
    "                            ignoreLeadingWhiteSpace=True,\n",
    "                            ignoreTrailingWhiteSpace=True\n",
    "                         ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a28e79-adc1-4e3e-b84a-630d84cb016f",
   "metadata": {},
   "source": [
    "# Data insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "287d506d-4e5a-4c30-b0ba-8770c27858be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- vote_average: double (nullable = true)\n",
      " |-- vote_count: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- release_date: timestamp (nullable = true)\n",
      " |-- revenue: long (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- adult: boolean (nullable = true)\n",
      " |-- backdrop_path: string (nullable = true)\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- spoken_languages: string (nullable = true)\n",
      " |-- keywords: string (nullable = true)\n",
      " |-- release_year: double (nullable = true)\n",
      " |-- Director: string (nullable = true)\n",
      " |-- AverageRating: double (nullable = true)\n",
      " |-- Poster_Link: string (nullable = true)\n",
      " |-- Certificate: string (nullable = true)\n",
      " |-- IMDB_Rating: double (nullable = true)\n",
      " |-- Meta_score: double (nullable = true)\n",
      " |-- Star1: string (nullable = true)\n",
      " |-- Star2: string (nullable = true)\n",
      " |-- Star3: string (nullable = true)\n",
      " |-- Star4: string (nullable = true)\n",
      " |-- Writer: string (nullable = true)\n",
      " |-- Director_of_Photography: string (nullable = true)\n",
      " |-- Producers: string (nullable = true)\n",
      " |-- Music_Composer: string (nullable = true)\n",
      " |-- genres_list: string (nullable = true)\n",
      " |-- Cast_list: string (nullable = true)\n",
      " |-- overview_sentiment: double (nullable = true)\n",
      " |-- all_combined_keywords: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a8101a-74fb-4bfb-b2fc-a5011389da69",
   "metadata": {},
   "source": [
    "# Selecting the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c20c3961-ecdb-40ed-858e-f3d88ffcacec",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = movie_df.select(\n",
    " 'id',\n",
    " 'title',\n",
    " 'revenue',\n",
    " 'budget',\n",
    " 'overview', \n",
    " 'poster_path',\n",
    " 'production_companies', \n",
    " 'release_year',\n",
    " 'Director',\n",
    " 'Star1',\n",
    " 'Star2',\n",
    " 'Star3',\n",
    " 'genres_list',\n",
    " 'all_combined_keywords'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96edbbb6-1523-4cd3-b38e-83c1fd95f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "movie_df = movie_df.withColumn(\"release_year\", col(\"release_year\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7643a49f-4ae2-40e4-a313-32666e0e8146",
   "metadata": {},
   "source": [
    "# Finding the number of null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "686facf1-d787-499d-b819-83511070a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,isnan,when,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10edef4f-eec2-4451-b71a-d0a38828e251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "1051990"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.filter(\"revenue == 0\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cec66a4-821a-4bbf-a893-0f8c3cdb2923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "1017840"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.filter(\"budget == 0\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d699354-e84f-4c59-a32b-7f2073a4ebde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+------+--------+-----------+--------------------+------------+--------+-------+-------+-------+\n",
      "| id|title|revenue|budget|overview|poster_path|production_companies|release_year|Director|  Star1|  Star2|  Star3|\n",
      "+---+-----+-------+------+--------+-----------+--------------------+------------+--------+-------+-------+-------+\n",
      "|  0|   94|      0|     0|  203560|     317840|              575706|      150556|       0|1041942|1069485|1069485|\n",
      "+---+-----+-------+------+--------+-----------+--------------------+------------+--------+-------+-------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_Columns=['id',\n",
    " 'title',\n",
    " 'revenue',\n",
    " 'budget',\n",
    " 'overview',\n",
    " 'poster_path',\n",
    " 'production_companies',\n",
    " 'release_year',\n",
    " 'Director',\n",
    " 'Star1',\n",
    " 'Star2',\n",
    " 'Star3']\n",
    "\n",
    "movie_df.select([count(when(col(c).contains('None') | \\\n",
    "                            col(c).contains('NULL') | \\\n",
    "                            (col(c) == '' ) | \\\n",
    "                            col(c).isNull() | \\\n",
    "                            isnan(c), c \n",
    "                           )).alias(c)\n",
    "                    for c in df_Columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f88a3627-577a-4e6e-9873-481f36f8dd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+\n",
      "|genres_list|all_combined_keywords|\n",
      "+-----------+---------------------+\n",
      "|          0|               172214|\n",
      "+-----------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_Columns=[\n",
    " 'genres_list',\n",
    " 'all_combined_keywords']\n",
    "movie_df.select([count(when(col(c).contains('None') | \\\n",
    "                            col(c).contains('NULL') | \\\n",
    "                            (col(c) == '' ) | \\\n",
    "                            (col(c) == '[]' ) | \\\n",
    "                            col(c).isNull() | \\\n",
    "                            isnan(c), c \n",
    "                           )).alias(c)\n",
    "                    for c in df_Columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed03474c-5fd8-4734-99a7-c5e2f243d8f5",
   "metadata": {},
   "source": [
    "# Removing duplicates, null and empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59c6c08a-d88a-4bb6-bbe4-8e4f574e1699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "1072255"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49adac08-4d5b-44eb-9f34-4932ff8e7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = movie_df.dropDuplicates([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0fa9fc2-ac7e-4c2c-bc0f-4a0d47aacd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = movie_df.na.drop(subset=['Title','release_year','overview','all_combined_keywords', 'poster_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fbda315-570e-4c6c-b7ec-6bec2634b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = movie_df.filter(~(movie_df['all_combined_keywords']== '[]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbdc85e6-8e74-410c-a207-6d740024948a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "604074"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f9bf2c-efa4-4367-abd2-d076ede6ec87",
   "metadata": {},
   "source": [
    "# Replacing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e5969-0525-42c5-b986-154f39a01bc3",
   "metadata": {},
   "source": [
    "### Note: a will be filtered in combined tags later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c8c7778-2e46-4558-8e8b-69c772444ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = movie_df.na.fill('a', ['production_companies','Star1', 'Star2','Star3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a104c-20fb-4052-8758-b0c3d9beb4ea",
   "metadata": {},
   "source": [
    "# Converting csv list to spark array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f205913c-5cf6-41d2-98e6-b0b0a4b49dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.functions import from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18a3c15b-1bff-407b-a74b-5653090840c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step: Parse array-like strings into ArrayType\n",
    "array_schema = T.ArrayType(T.StringType())\n",
    "movie_df = movie_df.withColumn(\"genres_list\", from_json(\"genres_list\", array_schema))\n",
    "movie_df = movie_df.withColumn(\"all_combined_keywords\", from_json(\"all_combined_keywords\", array_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eca07f81-1b51-4481-9093-7edfc68c1f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- revenue: long (nullable = true)\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- production_companies: string (nullable = false)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- Director: string (nullable = true)\n",
      " |-- Star1: string (nullable = false)\n",
      " |-- Star2: string (nullable = false)\n",
      " |-- Star3: string (nullable = false)\n",
      " |-- genres_list: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- all_combined_keywords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3b9eb7-dfb9-4c86-918e-3114b4243111",
   "metadata": {},
   "source": [
    "# After transforming the all_combined_keywords some null value are detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90f985f4-cc1e-44c2-9099-fdaadb924bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = movie_df.na.drop(subset=['all_combined_keywords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7600677-fdcb-49b5-bc9a-7eb3f31f40c9",
   "metadata": {},
   "source": [
    "# Converting the column to pyspark array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9200490-23f0-4a7a-8d79-bdc45c41f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b406fd7-cf84-4b33-be26-9bae1bf48e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = movie_df.withColumn(\"Director\", F.split(F.col(\"Director\"), \",\"))\n",
    "movie_df = movie_df.withColumn(\"production_companies\", F.split(F.col(\"production_companies\"), \",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9272a0a-977b-458b-8d05-a9cde6c0dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = movie_df.withColumn(\"overview\", F.split(F.col(\"overview\"), \",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1ec3b33-4e11-419d-87c5-c205bc433fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Star1, Star2, Star3, Director and Production companies to arrays \n",
    "movie_df = movie_df.withColumn(\"Star1\", F.array(F.col(\"Star1\"))) \\\n",
    "                   .withColumn(\"Star2\", F.array(F.col(\"Star2\"))) \\\n",
    "                   .withColumn(\"Star3\", F.array(F.col(\"Star3\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e3c0e86-c36f-4c1b-b2e0-f76545efade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = movie_df.withColumn(\n",
    "    \"crews\",\n",
    "    F.concat(F.col(\"Star1\"), F.col(\"Star2\"), F.col(\"Star3\"), F.col(\"Director\"), F.col(\"production_companies\") )\n",
    ")\n",
    "movie_df = movie_df.drop(\"Star1\", \"Star2\", \"Star3\", \"Director\", \"production_companies\")\n",
    "#movie_df.select('crews').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2f306b9-86c0-4e3e-9eca-cb0bb601b6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- revenue: long (nullable = true)\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- overview: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- genres_list: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- all_combined_keywords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- crews: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95371d8-8713-4cd1-a7d8-dbaa79beca8b",
   "metadata": {},
   "source": [
    "genres_list\n",
    "all_combined_keywords\n",
    "overview\n",
    "crews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2796a1-6e7b-4a6e-a62d-167821a1174d",
   "metadata": {},
   "source": [
    "# Removing the space in between the word while making them lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51022457-0f5c-4601-a9da-2cd572b66802",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = movie_df.withColumn(\"crews\", F.transform(F.col(\"crews\"), lambda x: F.regexp_replace(x, \"\\\\s+\", \"\")))\n",
    "movie_df = movie_df.withColumn(\"all_combined_keywords\", F.transform(F.col(\"all_combined_keywords\"), lambda x: F.regexp_replace(x, \"\\\\s+\", \"\")))\n",
    "movie_df = movie_df.withColumn(\"genres_list\", F.transform(F.col(\"genres_list\"), lambda x: F.regexp_replace(x, \"\\\\s+\", \"\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5806c867-153b-4800-aeba-a6f9a13cc7b0",
   "metadata": {},
   "source": [
    "# Concating the four feature to make tags column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "032abf39-86dd-45af-bc11-456f1e484037",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = movie_df.withColumn(\n",
    "    \"tags\",\n",
    "    F.concat(F.col(\"all_combined_keywords\"), F.col(\"genres_list\"), F.col(\"overview\"), F.col(\"crews\"))\n",
    ")\n",
    "movie_df = movie_df.drop(\"all_combined_keywords\",\"overview\",\"crews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f810d12-eb1a-4952-ba9f-8e6a0679fd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/24 22:32:32 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------+---------+--------------------+------------+--------------------+--------------------+\n",
      "| id|               title|  revenue|   budget|         poster_path|release_year|         genres_list|                tags|\n",
      "+---+--------------------+---------+---------+--------------------+------------+--------------------+--------------------+\n",
      "| 12|        Finding Nemo|940335536| 94000000|/ggQ6o8X5984OCh3k...|        2003| [Animation, Family]|[missingchild, s,...|\n",
      "| 16|  Dancer in the Dark| 40031879| 12800000|/8Wdd3fQfbbQeoSfW...|        2000|      [Drama, Crime]|[s, policeofficer...|\n",
      "| 18|   The Fifth Element|263920180| 90000000|/fPtlCO1yQtnoLHOw...|        1997|[Adventure, Fanta...|[cyberpunk, unint...|\n",
      "| 38|Eternal Sunshine ...| 72258126| 20000000|/5MwkWH9tYHv3mV9O...|        2004|[ScienceFiction, ...|[heartbroken, wat...|\n",
      "| 64|         Talk to Her| 64803131|        0|/p8ilqBhIT5YnKOf6...|        2002|    [Drama, Romance]|[matador(bullfigh...|\n",
      "| 67|        Paradise Now|  3395627|  2000000|/qWZkYa8VdcDZk8uz...|        2005|[Thriller, Crime,...|[unemployment, is...|\n",
      "| 70| Million Dollar Baby|216763646| 30000000|/2ti3l1OeB8G94yyq...|        2004|             [Drama]|[s, estrangement,...|\n",
      "| 74|   War of the Worlds|603873119|132000000|/6Biy7R9LfumYshur...|        2005|[Adventure, Thril...|[rareweekendvisit...|\n",
      "| 93| Anatomy of a Murder|  8000000|  2000000|/zMxLbSPpToTCc6yK...|        1959|[Crime, Drama, My...|[s, caserests, ha...|\n",
      "| 94|          Kunstgriff|        0|        0|/82CFTXepfmETr2C4...|        2002|            [Comedy]|[minutefilm, give...|\n",
      "|105|  Back to the Future|381109762| 19000000|/fNOH9f1aA7XRTzl1...|        1985|[Adventure, Comed...|[s, plutonium, ec...|\n",
      "|121|The Lord of the R...|926287400| 79000000|/5VTN0pR8gcqV3EPU...|        2002|[Adventure, Fanta...|[pippin, sam, ise...|\n",
      "|138|             Dracula|   700000|   355000|/ueVSPt7vAba0XScH...|        1931|[Horror, Drama, F...|[begins, pair, ba...|\n",
      "|141|        Donnie Darko|  7500000|  6000000|/j73zf3TjWR9j8pHL...|        2001|[Fantasy, Drama, ...|[plagued, commit,...|\n",
      "|146|Crouching Tiger, ...|213525736| 17000000|/iNDVBFNz4XyYzM9L...|        2000|[Adventure, Drama...|[revenge, s, qing...|\n",
      "|161|      Ocean's Eleven|450717150| 85000000|/hQQCdZrsHtZyR6Nb...|        2001|   [Thriller, Crime]|[s, ex, wife, nig...|\n",
      "|165|Back to the Futur...|332000000| 40000000|/hQq8xZe5uLjFzSBt...|        1989|[Adventure, Comed...|[thunderstorm, hi...|\n",
      "|186| Lucky Number Slevin| 56308881| 27000000|/x21s3p5wPww534nY...|        2006|[Drama, Thriller,...|[s, biggest, watc...|\n",
      "|194|              Am√©lie|173921954| 10000000|/nSxDa3M9aMvGVLoI...|        2001|   [Comedy, Romance]|[days, gift, hand...|\n",
      "|218|      The Terminator| 78371200|  6400000|/hzXSE66v6KthZ8nP...|        1984|[Action, Thriller...|[urbansetting, vi...|\n",
      "+---+--------------------+---------+---------+--------------------+------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "movie_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25071d9b-c221-47b2-82f9-c5b79e518420",
   "metadata": {},
   "source": [
    "# Things to Do\n",
    "\n",
    "1. **Tag with NLTK**  \n",
    "   Use the Natural Language Toolkit (NLTK) to process and extract tags from the data.\n",
    "\n",
    "2. **Apply CountVectorizer**  \n",
    "   Use `CountVectorizer` to convert the tags into a numerical feature matrix.\n",
    "\n",
    "3. **Compute Cosine Similarity**  \n",
    "   Perform a cross join (or use an efficient method) to calculate the cosine similarity between tag vectors.\n",
    "\n",
    "4. **Generate Recommendations**  \n",
    "   Create a new column that provides recommendations based on tag similarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a9770-803f-4030-9de5-8f627e690447",
   "metadata": {},
   "source": [
    "# Using Spark-NLP for Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f54b27a6-6fc1-4cab-886d-32532792a067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "25/08/24 22:32:47 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import Tokenizer, Normalizer, LemmatizerModel, StopWordsCleaner\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as F\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f282fc15-7af1-449c-8cdb-198df45b9816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[ | ]25/08/24 22:32:57 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/08/24 22:32:58 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/home/prajwal/Movie%20Recomender%20System/pyspark/venv/lib/python3.12/site-packages/pyspark/jars/spark-core_2.12-3.3.1.jar) to field java.util.regex.Pattern.pattern\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Join tags into a single string\n",
    "movie_df = movie_df.withColumn(\"tags_str\", F.concat_ws(\" \", F.col(\"tags\")))\n",
    "movie_df = movie_df.filter(F.trim(F.col(\"tags_str\")) != \"\")\n",
    "\n",
    "# Step 2: NLP Pipeline\n",
    "document = DocumentAssembler() \\\n",
    "    .setInputCol(\"tags_str\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Normalize: lowercase, remove punctuation, keep words & numbers only\n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"normalized\") \\\n",
    "    .setLowercase(True) \\\n",
    "    .setCleanupPatterns([\"[^a-zA-Z0-9]\"])   # keep only letters & numbers\n",
    "\n",
    "# Lemmatizer\n",
    "lemmatizer = LemmatizerModel.pretrained(\"lemma_antbnc\") \\\n",
    "    .setInputCols([\"normalized\"]) \\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "# Stopwords removal\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "    .setInputCols([\"lemma\"]) \\\n",
    "    .setOutputCol(\"clean_lemma\") \\\n",
    "    .setCaseSensitive(False)\n",
    "\n",
    "# Final array output\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"clean_lemma\"]) \\\n",
    "    .setOutputCols([\"tags_lemmatized\"]) \\\n",
    "    .setOutputAsArray(True)\n",
    "\n",
    "# Step 3: Build pipeline\n",
    "pipeline = Pipeline(stages=[\n",
    "    document, tokenizer, normalizer,\n",
    "    lemmatizer, stopwords_cleaner, finisher\n",
    "])\n",
    "\n",
    "# Step 4: Fit + Transform\n",
    "model = pipeline.fit(movie_df)\n",
    "movie_df = model.transform(movie_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9d4fa4c-db3b-4b2d-b50c-9b3704f8a311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spark-nlp==6.0.2 in /home/prajwal/Movie Recomender System/pyspark/venv/lib/python3.12/site-packages (6.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install spark-nlp==6.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b159095-90f5-405d-860d-79f306065225",
   "metadata": {},
   "source": [
    "# Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45d85229-85a8-467e-b78a-c6343bece02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import  CountVectorizer\n",
    "cv = CountVectorizer(inputCol=\"tags_lemmatized\", outputCol=\"features\")\n",
    "cv_model = cv.fit(movie_df)\n",
    "movie_df = cv_model.transform(movie_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ed4b8-0f40-4f66-a2e8-79417a7685a2",
   "metadata": {},
   "source": [
    "# Normalizing the vector, lsh for distance then creating the recommendation \n",
    "# column using window function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c69bea54-d9d2-422a-9179-05447f862b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer, BucketedRandomProjectionLSH\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a720e80f-d1b9-4c18-8a78-84764a26f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Normalize features (so cosine similarity works via L2 distance)\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"norm_features\", p=2.0)\n",
    "movie_df = normalizer.transform(movie_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c0ee479-fb64-4ff2-b1ca-0fe0322dcede",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = movie_df.drop(\"tags\", \"tags_str\",\"tags_lemmatized\",\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e109f84d-f9f3-4263-be74-693fcb6afcbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/24 22:35:41 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "+---+--------------------+---------+---------+--------------------+------------+--------------------+--------------------+\n",
      "| id|               title|  revenue|   budget|         poster_path|release_year|         genres_list|       norm_features|\n",
      "+---+--------------------+---------+---------+--------------------+------------+--------------------+--------------------+\n",
      "| 12|        Finding Nemo|940335536| 94000000|/ggQ6o8X5984OCh3k...|        2003| [Animation, Family]|(262144,[6,9,18,2...|\n",
      "| 16|  Dancer in the Dark| 40031879| 12800000|/8Wdd3fQfbbQeoSfW...|        2000|      [Drama, Crime]|(262144,[1,3,7,8,...|\n",
      "| 18|   The Fifth Element|263920180| 90000000|/fPtlCO1yQtnoLHOw...|        1997|[Adventure, Fanta...|(262144,[6,19,34,...|\n",
      "| 38|Eternal Sunshine ...| 72258126| 20000000|/5MwkWH9tYHv3mV9O...|        2004|[ScienceFiction, ...|(262144,[3,7,49,5...|\n",
      "| 64|         Talk to Her| 64803131|        0|/p8ilqBhIT5YnKOf6...|        2002|    [Drama, Romance]|(262144,[3,4,10,4...|\n",
      "| 67|        Paradise Now|  3395627|  2000000|/qWZkYa8VdcDZk8uz...|        2005|[Thriller, Crime,...|(262144,[3,21,42,...|\n",
      "| 70| Million Dollar Baby|216763646| 30000000|/2ti3l1OeB8G94yyq...|        2004|             [Drama]|(262144,[1,3,22,4...|\n",
      "| 74|   War of the Worlds|603873119|132000000|/6Biy7R9LfumYshur...|        2005|[Adventure, Thril...|(262144,[6,14,38,...|\n",
      "| 93| Anatomy of a Murder|  8000000|  2000000|/zMxLbSPpToTCc6yK...|        1959|[Crime, Drama, My...|(262144,[3,9,47,6...|\n",
      "| 94|          Kunstgriff|        0|        0|/82CFTXepfmETr2C4...|        2002|            [Comedy]|(262144,[0,2,13,8...|\n",
      "|105|  Back to the Future|381109762| 19000000|/fNOH9f1aA7XRTzl1...|        1985|[Adventure, Comed...|(262144,[13,15,21...|\n",
      "|121|The Lord of the R...|926287400| 79000000|/5VTN0pR8gcqV3EPU...|        2002|[Adventure, Fanta...|(262144,[23,34,89...|\n",
      "|138|             Dracula|   700000|   355000|/ueVSPt7vAba0XScH...|        1931|[Horror, Drama, F...|(262144,[3,29,42,...|\n",
      "|141|        Donnie Darko|  7500000|  6000000|/j73zf3TjWR9j8pHL...|        2001|[Fantasy, Drama, ...|(262144,[3,79,83,...|\n",
      "|146|Crouching Tiger, ...|213525736| 17000000|/iNDVBFNz4XyYzM9L...|        2000|[Adventure, Drama...|(262144,[1,3,34,4...|\n",
      "|161|      Ocean's Eleven|450717150| 85000000|/hQQCdZrsHtZyR6Nb...|        2001|   [Thriller, Crime]|(262144,[23,62,68...|\n",
      "|165|Back to the Futur...|332000000| 40000000|/hQq8xZe5uLjFzSBt...|        1989|[Adventure, Comed...|(262144,[13,15,18...|\n",
      "|186| Lucky Number Slevin| 56308881| 27000000|/x21s3p5wPww534nY...|        2006|[Drama, Thriller,...|(262144,[3,8,26,3...|\n",
      "|194|              Am√©lie|173921954| 10000000|/nSxDa3M9aMvGVLoI...|        2001|   [Comedy, Romance]|(262144,[7,11,13,...|\n",
      "|218|      The Terminator| 78371200|  6400000|/hzXSE66v6KthZ8nP...|        1984|[Action, Thriller...|(262144,[34,36,73...|\n",
      "+---+--------------------+---------+---------+--------------------+------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "movie_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16b371c8-0e8f-498f-a9c2-41d0a650b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- revenue: long (nullable = true)\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- genres_list: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- norm_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1a57bba-7e81-4402-8ee1-6b0260ca8d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/24 22:35:57 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.filter(F.col(\"norm_features\").isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a990ad-89a4-42b1-9f67-32a544a6b8b7",
   "metadata": {},
   "source": [
    "# Setup LSH with normalized vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20f641cf-6392-4098-9288-521564707a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh = BucketedRandomProjectionLSH(\n",
    "    inputCol=\"norm_features\",\n",
    "    outputCol=\"hashes\",\n",
    "    bucketLength=2,   # tune\n",
    "    numHashTables=4    # tune\n",
    ")\n",
    "lsh_model = lsh.fit(movie_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c4336c-91ae-4c15-847d-0a015cf5dcb4",
   "metadata": {},
   "source": [
    "# Writing model \n",
    "# Writing dataframe to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1d1552a-bf04-4842-a981-a4708c1d0219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "movie_metadata = movie_df.select('id','title','poster_path','release_year')\n",
    "output_dir = r\"/home/prajwal/Movie-Data/Transform\"\n",
    "movie_metadata.write.mode(\"overwrite\").parquet(os.path.join(output_dir, \"stage1\", \"movie_metadata\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28cda02d-06a1-4fc7-ba68-17c970a3d127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/20 08:37:12 WARN TaskSetManager: Stage 42 contains a task of very large size (8365 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "model_path = r\"/home/prajwal/Movie-Data/Transform/stage2/lsh_model\"\n",
    "lsh_model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bba833d0-6de0-4b4b-b595-a64e747b5169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "master = movie_df.select('id','title','poster_path','revenue','budget','release_year','genres_list')\n",
    "output_dir = r\"/home/prajwal/Movie-Data/Transform\"\n",
    "master.write.mode(\"overwrite\").parquet(os.path.join(output_dir, \"stage3\", \"master_table\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "838eb682-b19e-4f60-91fa-b78eac6cfe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/24 22:38:11 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "vector = movie_df.select('id','norm_features')\n",
    "output_dir = r\"/home/prajwal/Movie-Data/Transform\"\n",
    "vector.write.mode(\"overwrite\").parquet(os.path.join(output_dir, \"stage4\", \"vector\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "08fcf6db-6b8a-40b0-995b-065179cfbac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_metadata.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf2dc8b8-6616-40bf-b4d2-51391bca57eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- revenue: long (nullable = true)\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- genres_list: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "master.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2f5439-2f2a-47ce-8c30-dacc9c6291cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dcb9a9c-34f2-47aa-a46b-9528930fc3f7",
   "metadata": {},
   "source": [
    "## Method to return the similar id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bd2922c-56e3-4a4e-beb0-8f60c28bc0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(movie_id, top_k=5):\n",
    "    # Get query vector\n",
    "    movie_vector = movie_df.filter(F.col(\"id\") == movie_id).limit(1)\n",
    "\n",
    "    if movie_vector.count() == 0:\n",
    "        print(f\"Movie ID {movie_id} not found.\")\n",
    "        return []\n",
    "\n",
    "    # Extract the vector (no UDF, just collect once)\n",
    "    query_vec = movie_vector.first()[\"norm_features\"]\n",
    "\n",
    "    # Find nearest neighbors\n",
    "    neighbors = lsh_model.approxNearestNeighbors(\n",
    "        dataset=movie_df,\n",
    "        key=query_vec,\n",
    "        numNearestNeighbors=top_k + 1  # +1 because it includes the same movie\n",
    "    )\n",
    "\n",
    "    # Drop the movie itself and take top_k\n",
    "    result = (neighbors\n",
    "              .filter(F.col(\"id\") != movie_id)\n",
    "              .select(\"id\")\n",
    "              .limit(top_k))\n",
    "\n",
    "    # Return as a plain Python list\n",
    "    return [row[\"id\"] for row in result.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2788e3-767b-4c8a-935e-bf072c067177",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1654b6ee-9b8b-4827-8d2b-3fb5226ce9ec",
   "metadata": {},
   "source": [
    "## Avengers: Infinity War"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d5b53ee-7238-4c95-a9b1-3ad9528fe580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 135:============================>                            (4 + 4) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|    id|\n",
      "+------+\n",
      "|299536|\n",
      "+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "movie_df.filter('title == \"Avengers: Infinity War\"').limit(1).select('id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d82783ee-f386-4cb6-bc5a-0ca9938bb2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/20 08:50:53 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 67:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/20 08:51:07 WARN DAGScheduler: Broadcasting large task binary with size 11.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:==================================================>       (7 + 1) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/20 08:54:24 WARN DAGScheduler: Broadcasting large task binary with size 11.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[299534, 408647, 1215047, 825463, 52795]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(299536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2af5f9ec-eedb-4c82-8442-0f277a16cbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 142:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------------------------------------------------+-------------------------------------------------------+\n",
      "|id     |title                                                                             |genres_list                                            |\n",
      "+-------+----------------------------------------------------------------------------------+-------------------------------------------------------+\n",
      "|52795  |Doraemon: Nobita's New Great Adventure Into the Underworld - The Seven Magic Users|[Family, Adventure, Animation, ScienceFiction, Fantasy]|\n",
      "|299534 |Avengers: Endgame                                                                 |[Adventure, ScienceFiction, Action]                    |\n",
      "|408647 |Teen Titans: The Judas Contract                                                   |[ScienceFiction, Animation, Action]                    |\n",
      "|825463 |Tenkai Knights - Rise of the Knights                                              |[Unknown]                                              |\n",
      "|1215047|Avengers Assemble: Thor                                                           |[Unknown]                                              |\n",
      "+-------+----------------------------------------------------------------------------------+-------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "movie_ids = [299534, 408647, 1215047, 825463, 52795]\n",
    "\n",
    "movie_df.filter(col(\"id\").isin(movie_ids)).limit(5).select('id','title','genres_list').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f19494-f21c-4101-8227-928d87d41dac",
   "metadata": {},
   "source": [
    "## Avengers: Endgame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "128e612a-c671-4d31-aa45-41384e112a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 129:============================>                            (4 + 4) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|    id|\n",
      "+------+\n",
      "|299534|\n",
      "+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "movie_df.filter('title == \"Avengers: Endgame\"').limit(1).select('id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f497686f-03ff-4619-9c99-9ada2e6ee021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 86:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/20 08:59:58 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/20 09:00:12 WARN DAGScheduler: Broadcasting large task binary with size 11.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 91:==================================================>       (7 + 1) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/20 09:04:09 WARN DAGScheduler: Broadcasting large task binary with size 11.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[912223, 299536, 890235, 521720, 1234510]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(299534)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18d9299d-43ea-4da9-9638-9e36043b94d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 139:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------------+-------------------------------------------+\n",
      "|id     |title                                         |genres_list                                |\n",
      "+-------+----------------------------------------------+-------------------------------------------+\n",
      "|299536 |Avengers: Infinity War                        |[Adventure, Action, ScienceFiction]        |\n",
      "|521720 |Avengers Grimm: Time Wars                     |[Action, Adventure, Fantasy]               |\n",
      "|890235 |The Silent Avenger                            |[Action, Adventure]                        |\n",
      "|912223 |Los Vengadores Chiflados                      |[Comedy, Action, Adventure, ScienceFiction]|\n",
      "|1234510|Better Than You - Complete CM Punk vs MJF Feud|[Action]                                   |\n",
      "+-------+----------------------------------------------+-------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "movie_ids = [912223, 299536, 890235, 521720, 1234510]\n",
    "\n",
    "movie_df.filter(col(\"id\").isin(movie_ids)).limit(5).select('id','title','genres_list').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05693d3-79b8-40db-a72a-77c26722fcc3",
   "metadata": {},
   "source": [
    "## Harry Potter and the Philosopher's Stone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1371bc0c-0abf-4ca8-9b94-0520025a2387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 98:====================================>                     (5 + 3) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|671|\n",
      "+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "movie_df.filter(\"title == \\\"Harry Potter and the Philosopher's Stone\\\"\") \\\n",
    "        .limit(1) \\\n",
    "        .select(\"id\") \\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e58e38b-265c-4a44-af9a-00288289458f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 108:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/20 09:09:56 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 111:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/20 09:10:08 WARN DAGScheduler: Broadcasting large task binary with size 11.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 113:=================================================>       (7 + 1) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/20 09:14:03 WARN DAGScheduler: Broadcasting large task binary with size 11.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1324149, 466774, 673, 674, 693425]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(671)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d248f9c7-40cb-4c31-bb69-f3c9e0ca22a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 118:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------+--------------------+\n",
      "|id     |title                                   |genres_list         |\n",
      "+-------+----------------------------------------+--------------------+\n",
      "|673    |Harry Potter and the Prisoner of Azkaban|[Adventure, Fantasy]|\n",
      "|674    |Harry Potter and the Goblet of Fire     |[Adventure, Fantasy]|\n",
      "|466774 |Raising Zoey                            |[Unknown]           |\n",
      "|693425 |After School Sextivities                |[Unknown]           |\n",
      "|1324149|Harry Potter and the Forbidden Journey  |[Adventure]         |\n",
      "+-------+----------------------------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "movie_ids = [1324149, 466774, 673, 674, 693425]\n",
    "\n",
    "movie_df.filter(col(\"id\").isin(movie_ids)).limit(5).select('id','title','genres_list').show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
